
# Nhatot.com Data Crawler Tool

A custom web scraping tool designed to extract data from [Nhatot.com](https://nhatot.com), a popular real estate website in Vietnam.<br>
This tool helps automate the process of collecting real estate data for research, analysis, or data enrichment purposes.

> âš ï¸ **Disclaimer**: This tool is for educational and research purposes only. Make sure you comply with NhaTot.com's Terms of Service before using it.

---

## ğŸ“¦ Features

- Scrape listing data (title, price, location, description, etc.)
- Easy to extend and customize

---

## ğŸ›  Installation

<b>1. Clone the repository:</b>

```bash
    git clone https://github.com/ManaxGIT/nhatot_crawler
    cd nhatot_crawler
```

<b>2. Create and activate a virtual environment:</b>
*(optional but strongly recommended)*

* create virtual environment
```bash
    python -m venv .venv
```
* run virtual environment
    * MacOS/Linux user
        ```bash
        source .venv/bin/activate
        ```
    * Window user
        ```bash
        venv\Scripts\activate.bat
        ```

<b>3. Install dependencies:</b>

```bash
    pip install -r requirements.txt
```

---

## ğŸ“ Folder Structure

```
nhatot-crawler/
â”‚
â”œâ”€â”€ scripts/               # Include all crawl script files
â”‚   â”œâ”€â”€ home_gathering.py  # Use to crawl informations on home page
â”‚   â”œâ”€â”€ link_gathering.py  # Use to crawl links on home page
â”‚   â”œâ”€â”€ output_can_ho.py   # Crawl Can Ho informations
â”‚   â”œâ”€â”€ output_dat.py      # Crawl Dat informations 
â”‚   â””â”€â”€ output_nha_o.py    # Crawl Nha O informations
â”‚
â”œâ”€â”€ link_output/           # link-output location
â”‚
â”œâ”€â”€ scraped_data/          # real estate data output location
â”‚
â”œâ”€â”€ thread/                # Contain logic to increase productivity
â”‚
â”œâ”€â”€ GUI.py                 # GUI of the tool
â”œâ”€â”€ requirements.txt       # Python package dependencies
â”œâ”€â”€ INSTRUCTION.docx       # Tool logic explaination
â””â”€â”€ README.md              # Project guide
```

---

## ğŸš€ Use manual

* run the GUI
```bash
    python3 GUI.py
```

* <b>If you don't have the link file (which you usually are)</b>
  - Access [Nhatot.com](https://nhatot.com). From *Danh má»¥c*, select either *cÄƒn há»™/chung cÆ°*, *nhÃ  á»Ÿ*, *Ä‘áº©t*. Copy the link
  - Input the link into *Link danh má»¥c tin*.
  - Choose number of pages you want to get data from in *Sá»‘ trang cáº§n crawl*.
  - Input the name of the output link file into *TÃªn file CSV cá»§a link*. This could be reuse later.
  - Input the name of the file which data are saved into *TÃªn file sau khi scrape*.
  - Select *Loáº¡i dá»¯ liá»‡u* same as the website link you copied before.
  - Click *Báº¯t Ä‘áº§u* button

* <b>If you already have the link file</b>
  - Change mode to *Chá»‰ scrape tá»« link Ä‘Ã£ cÃ³*.
  - Input link file location into *TÃªn file CSV cá»§a link*
  - Input the name of the file which data are saved into *TÃªn file sau khi scrape*.
  - Select *Loáº¡i dá»¯ liá»‡u* same as the inputted link file.
  - Click *Báº¯t Ä‘áº§u* button

---

## âš–ï¸ Legal & Ethical Considerations

This tool is intended **only for educational, academic, or personal research use**. Web scraping may violate a websiteâ€™s terms of service. It is your responsibility to ensure that your use of this tool does not breach:

- NhaTot.comâ€™s [Terms of Use](https://nhatot.com/terms)
- Vietnamese or international data privacy laws
- The rights of any third party

Avoid aggressive crawling to reduce the risk of IP bans and server overload.

---

## ğŸ“§ Contact

For questions or collaboration:
- Email: mancv.22it@vku.udn.vn | huycq.22it@vku.udn.vn
- GitHub: [Manax](https://github.com/ManaxGIT/) | [Hy](https://github.com/huycq2004)

